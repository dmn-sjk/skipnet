exp_name: skip

cmd: train # [train, test, tune]
arch: cifar10_rnn_gate_rl_38
gate_type: rnn # [rnn, ff]
dataset: cifar10c # [cifar10, cifar100],
data_root: /datasets
workers: 4
iters: 10000
start_iter: 0
batch_size: 128
lr_sp: 0.1
lr_rl: 1.e-4
momentum: 0.9
weight_decay: 1.e-4
print_freq: 100
resume: '' # path to  latest checkpoint
pretrained: False
step_ratio: 0.1 # ratio for learning rate reduction'
warm_up: False
save_folder: save_checkpoints/cl
eval_every: 60
fine_tune: False # fine tune model
seed: 1

# rl params
alpha: 0.1 # 0.1 # Reward magnitude for the average number of skipped layers'
temperature: 1 # temperature of softmax
rl_weight: 0.01
gamma: 1 # discount factor, default
restart: False # restart training

severity: 5
corruption: gaussian_noise