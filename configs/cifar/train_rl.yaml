exp_name: alpha0

cmd: train # [train, test, tune]
arch: cifar10_rnn_gate_rl_38
gate_type: rnn # [rnn, ff]
dataset: cifar10c # [cifar10, cifar100],
data_root: /datasets
workers: 4
iters: 10000
start_iter: 0
batch_size: 128
lr: 1.e-4
momentum: 0.9
weight_decay: 1.e-4
print_freq: 100
resume: save_checkpoints/office_home_rnn_gate_34/cifar10c_all/skip/model_best.pth.tar # path to  latest checkpoint
pretrained: False
step_ratio: 0.1 # ratio for learning rate reduction'
warm_up: False
save_folder: save_checkpoints
eval_every: 60
fine_tune: False # fine tune model
seed: 1

# rl params
alpha: 0.0 # 0.1 # Reward magnitude for the average number of skipped layers'
temperature: 1 # temperature of softmax
rl_weight: 0.01
gamma: 1 # discount factor, default
restart: False # restart training

severity: 5
domain: gaussian_noise